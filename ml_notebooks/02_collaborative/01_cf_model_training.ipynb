{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "742d6d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix, save_npz\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4efe552f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 1,464 interactions\n",
      "Unique users: 1,193\n",
      "Unique items: 1,350\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AG3D6O4STAQKAY2UVGEUV46KN35Q,AHMY5CWJMMK5BJRBB...</td>\n",
       "      <td>B07JW9H4J1</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AECPFYFQVRUWC3KGNLJIOREFP5LQ,AGYYVPDD7YG7FYNBX...</td>\n",
       "      <td>B098NS6PVG</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGU3BBQ2V2DDAMOAKGFAWDDQ6QHA,AESFLDV2PT363T2AQ...</td>\n",
       "      <td>B096MSW6CT</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEWAZDZZJLQUYVOVGBEUKSLXHQ5A,AG5HTSFRRE6NL3M5S...</td>\n",
       "      <td>B08HDJ86NZ</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AE3Q6KSUK5P75D5HFYHCRAOLODSA,AFUGIFH5ZAFXRDSZH...</td>\n",
       "      <td>B08CF3B7N1</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             user_id  product_id  rating\n",
       "0  AG3D6O4STAQKAY2UVGEUV46KN35Q,AHMY5CWJMMK5BJRBB...  B07JW9H4J1     4.2\n",
       "1  AECPFYFQVRUWC3KGNLJIOREFP5LQ,AGYYVPDD7YG7FYNBX...  B098NS6PVG     4.0\n",
       "2  AGU3BBQ2V2DDAMOAKGFAWDDQ6QHA,AESFLDV2PT363T2AQ...  B096MSW6CT     3.9\n",
       "3  AEWAZDZZJLQUYVOVGBEUKSLXHQ5A,AG5HTSFRRE6NL3M5S...  B08HDJ86NZ     4.2\n",
       "4  AE3Q6KSUK5P75D5HFYHCRAOLODSA,AFUGIFH5ZAFXRDSZH...  B08CF3B7N1     4.2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your preprocessed data\n",
    "# Adjust the path based on your actual file location\n",
    "df = pd.read_csv('../../data/cf_interactions.csv')\n",
    "\n",
    "print(f\"Dataset loaded: {len(df):,} interactions\")\n",
    "print(f\"Unique users: {df['user_id'].nunique():,}\")\n",
    "print(f\"Unique items: {df['product_id'].nunique():,}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f062392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users encoded: 1193\n",
      "Items encoded: 1350\n",
      "\n",
      "Example mappings:\n",
      "                                             user_id  user_code  product_id  \\\n",
      "0  AG3D6O4STAQKAY2UVGEUV46KN35Q,AHMY5CWJMMK5BJRBB...        623  B07JW9H4J1   \n",
      "1  AECPFYFQVRUWC3KGNLJIOREFP5LQ,AGYYVPDD7YG7FYNBX...         88  B098NS6PVG   \n",
      "2  AGU3BBQ2V2DDAMOAKGFAWDDQ6QHA,AESFLDV2PT363T2AQ...        848  B096MSW6CT   \n",
      "3  AEWAZDZZJLQUYVOVGBEUKSLXHQ5A,AG5HTSFRRE6NL3M5S...        254  B08HDJ86NZ   \n",
      "4  AE3Q6KSUK5P75D5HFYHCRAOLODSA,AFUGIFH5ZAFXRDSZH...         17  B08CF3B7N1   \n",
      "\n",
      "   item_code  \n",
      "0        346  \n",
      "1        847  \n",
      "2        818  \n",
      "3        643  \n",
      "4        588  \n"
     ]
    }
   ],
   "source": [
    "# Create categorical codes for users and items\n",
    "df['user_code'] = df['user_id'].astype('category').cat.codes\n",
    "df['item_code'] = df['product_id'].astype('category').cat.codes\n",
    "\n",
    "# Save mappings for later use (to convert codes back to IDs)\n",
    "user_mapping = df[['user_code', 'user_id']].drop_duplicates().set_index('user_code').sort_index()\n",
    "item_mapping = df[['item_code', 'product_id']].drop_duplicates().set_index('item_code').sort_index()\n",
    "\n",
    "print(f\"Users encoded: {df['user_code'].nunique()}\")\n",
    "print(f\"Items encoded: {df['item_code'].nunique()}\")\n",
    "print(\"\\nExample mappings:\")\n",
    "print(df[['user_id', 'user_code', 'product_id', 'item_code']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0a057d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "DATA SPLIT SUMMARY\n",
      "==================================================\n",
      "Total interactions: 1,464\n",
      "\n",
      "Train set: 1,171 (80.0%)\n",
      "Test set:  293 (20.0%)\n",
      "\n",
      "Train users: 978\n",
      "Test users:  273\n",
      "\n",
      "Train items: 1,092\n",
      "Test items:  288\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train and test sets\n",
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,      # 20% for testing\n",
    "    random_state=42,    # For reproducibility\n",
    "    stratify=None       # Can stratify by user if needed\n",
    ")\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"DATA SPLIT SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total interactions: {len(df):,}\")\n",
    "print(f\"\\nTrain set: {len(train_df):,} ({len(train_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"Test set:  {len(test_df):,} ({len(test_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"\\nTrain users: {train_df['user_code'].nunique():,}\")\n",
    "print(f\"Test users:  {test_df['user_code'].nunique():,}\")\n",
    "print(f\"\\nTrain items: {train_df['item_code'].nunique():,}\")\n",
    "print(f\"Test items:  {test_df['item_code'].nunique():,}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efb43631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix dimensions: 1,193 users × 1,350 items\n",
      "Total possible interactions: -27,850\n",
      "\n",
      "Using ratings as interaction values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22788\\1903194527.py:6: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  print(f\"Total possible interactions: {n_users * n_items:,}\")\n"
     ]
    }
   ],
   "source": [
    "# Get matrix dimensions (same for both train and test)\n",
    "n_users = df['user_code'].max() + 1\n",
    "n_items = df['item_code'].max() + 1\n",
    "\n",
    "print(f\"Matrix dimensions: {n_users:,} users × {n_items:,} items\")\n",
    "print(f\"Total possible interactions: {n_users * n_items:,}\")\n",
    "\n",
    "# Determine what values to use\n",
    "# If you have ratings, use them. Otherwise, use 1 (binary interaction)\n",
    "if 'rating' in train_df.columns:\n",
    "    print(\"\\nUsing ratings as interaction values\")\n",
    "    train_values = train_df['rating'].values\n",
    "    test_values = test_df['rating'].values\n",
    "else:\n",
    "    print(\"\\nNo ratings found - using binary interactions (1 = interacted)\")\n",
    "    train_values = np.ones(len(train_df))\n",
    "    test_values = np.ones(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e6f51d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN MATRIX:\n",
      "  Shape: (1193, 1350)\n",
      "  Non-zero entries: 1,171\n",
      "  Sparsity: 104.2047%\n",
      "  Memory: 0.01 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22788\\4082809297.py:10: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  print(f\"  Sparsity: {(1 - train_matrix.nnz / (n_users * n_items)) * 100:.4f}%\")\n"
     ]
    }
   ],
   "source": [
    "# Create TRAIN interaction matrix\n",
    "train_matrix = coo_matrix(\n",
    "    (train_values, (train_df['user_code'], train_df['item_code'])),\n",
    "    shape=(n_users, n_items)\n",
    ")\n",
    "\n",
    "print(\"TRAIN MATRIX:\")\n",
    "print(f\"  Shape: {train_matrix.shape}\")\n",
    "print(f\"  Non-zero entries: {train_matrix.nnz:,}\")\n",
    "print(f\"  Sparsity: {(1 - train_matrix.nnz / (n_users * n_items)) * 100:.4f}%\")\n",
    "print(f\"  Memory: {train_matrix.data.nbytes / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32d464fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST MATRIX:\n",
      "  Shape: (1193, 1350)\n",
      "  Non-zero entries: 293\n",
      "  Sparsity: 101.0521%\n",
      "  Memory: 0.00 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22788\\3699826290.py:10: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  print(f\"  Sparsity: {(1 - test_matrix.nnz / (n_users * n_items)) * 100:.4f}%\")\n"
     ]
    }
   ],
   "source": [
    "# Create TEST interaction matrix\n",
    "test_matrix = coo_matrix(\n",
    "    (test_values, (test_df['user_code'], test_df['item_code'])),\n",
    "    shape=(n_users, n_items)\n",
    ")\n",
    "\n",
    "print(\"TEST MATRIX:\")\n",
    "print(f\"  Shape: {test_matrix.shape}\")\n",
    "print(f\"  Non-zero entries: {test_matrix.nnz:,}\")\n",
    "print(f\"  Sparsity: {(1 - test_matrix.nnz / (n_users * n_items)) * 100:.4f}%\")\n",
    "print(f\"  Memory: {test_matrix.data.nbytes / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edea9ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized with parameters:\n",
      "  Factors: 50\n",
      "  Regularization: 0.1\n",
      "  Iterations: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\miniconda3\\Lib\\site-packages\\threadpoolctl.py:1226: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "c:\\Users\\hp\\miniconda3\\Lib\\site-packages\\implicit\\cpu\\als.py:95: RuntimeWarning: Intel MKL BLAS is configured to use 12 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'MKL_NUM_THREADS=1' or by callng 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having MKL use a threadpool can lead to severe performance issues\n",
      "  check_blas_config()\n"
     ]
    }
   ],
   "source": [
    "# Initialize the ALS model\n",
    "model = AlternatingLeastSquares(\n",
    "    factors=50,              # Number of latent factors\n",
    "    regularization=0.1,      # L2 regularization\n",
    "    iterations=20,           # Number of training iterations\n",
    "    random_state=42,         # For reproducibility\n",
    "    use_gpu=False            # Set to True if you have GPU\n",
    ")\n",
    "\n",
    "print(\"Model initialized with parameters:\")\n",
    "print(f\"  Factors: {model.factors}\")\n",
    "print(f\"  Regularization: {model.regularization}\")\n",
    "print(f\"  Iterations: {model.iterations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "182b5fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\miniconda3\\Lib\\site-packages\\implicit\\utils.py:164: ParameterWarning: Method expects CSR input, and was passed coo_matrix instead. Converting to CSR took 0.001986265182495117 seconds\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model...\n",
      "This may take a few minutes depending on data size...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 420.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Training complete!\n",
      "\n",
      "Model learned:\n",
      "  User factors shape: (1193, 50)\n",
      "  Item factors shape: (1350, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model on TRAIN data only\n",
    "print(\"\\nTraining model...\")\n",
    "print(\"This may take a few minutes depending on data size...\\n\")\n",
    "\n",
    "model.fit(train_matrix)\n",
    "\n",
    "print(\"✓ Training complete!\")\n",
    "print(f\"\\nModel learned:\")\n",
    "print(f\"  User factors shape: {model.user_factors.shape}\")\n",
    "print(f\"  Item factors shape: {model.item_factors.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c44354a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample recommendations for user 0:\n",
      "\n",
      "Item Code | Score\n",
      "-------------------------\n",
      "      589 | 0.1319 | B08CF3D7QR\n",
      "     1282 | 0.1017 | B0BC9BW512\n",
      "     1140 | 0.1017 | B0B1YZX72F\n",
      "     1139 | 0.1017 | B0B1YZ9CB8\n",
      "     1138 | 0.1017 | B0B1YY6JJL\n",
      "\n",
      "✓ Model is working!\n"
     ]
    }
   ],
   "source": [
    "# Test recommendation for user 0\n",
    "test_user = 0\n",
    "\n",
    "# Get recommendations\n",
    "recommendations = model.recommend(\n",
    "    test_user,\n",
    "    train_matrix.tocsr()[test_user],\n",
    "    N=5,\n",
    "    filter_already_liked_items=True\n",
    ")\n",
    "\n",
    "print(f\"Sample recommendations for user {test_user}:\")\n",
    "print(\"\\nItem Code | Score\")\n",
    "print(\"-\" * 25)\n",
    "for item_id, score in zip(recommendations[0], recommendations[1]):\n",
    "    product_id = item_mapping.loc[item_id, 'product_id']\n",
    "    print(f\"{item_id:9d} | {score:.4f} | {product_id}\")\n",
    "\n",
    "print(\"\\n✓ Model is working!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b97f0a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model and data...\n",
      "\n",
      "✓ Saved: als_model.pkl\n",
      "✓ Saved: train_matrix.npz\n",
      "✓ Saved: test_matrix.npz\n",
      "✓ Saved: user_mapping.csv\n",
      "✓ Saved: item_mapping.csv\n",
      "✓ Saved: metadata.pkl\n",
      "\n",
      "==================================================\n",
      "ALL FILES SAVED SUCCESSFULLY!\n",
      "==================================================\n",
      "\n",
      "Next step: Run 02_cf_evaluation.ipynb to evaluate the model\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving model and data...\\n\")\n",
    "\n",
    "# 1. Save the trained model\n",
    "with open('../../ml_service/app/models/collaborative_filtering/als_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "print(\"✓ Saved: als_model.pkl\")\n",
    "\n",
    "# 2. Save train matrix (needed for making recommendations)\n",
    "save_npz('../../ml_service/app/models/collaborative_filtering/train_matrix.npz', train_matrix.tocsr())\n",
    "print(\"✓ Saved: train_matrix.npz\")\n",
    "\n",
    "# 3. Save test matrix (for evaluation)\n",
    "save_npz('../../ml_service/app/models/collaborative_filtering/test_matrix.npz', test_matrix.tocsr())\n",
    "print(\"✓ Saved: test_matrix.npz\")\n",
    "\n",
    "# 4. Save user mapping\n",
    "user_mapping.to_csv('../../ml_service/app/models/collaborative_filtering/user_mapping.csv')\n",
    "print(\"✓ Saved: user_mapping.csv\")\n",
    "\n",
    "# 5. Save item mapping\n",
    "item_mapping.to_csv('../../ml_service/app/models/collaborative_filtering/item_mapping.csv')\n",
    "print(\"✓ Saved: item_mapping.csv\")\n",
    "\n",
    "# 6. Save model metadata\n",
    "metadata = {\n",
    "    'n_users': n_users,\n",
    "    'n_items': n_items,\n",
    "    'train_size': len(train_df),\n",
    "    'test_size': len(test_df),\n",
    "    'factors': model.factors,\n",
    "    'regularization': model.regularization,\n",
    "    'iterations': model.iterations\n",
    "}\n",
    "with open('../../ml_service/app/models/collaborative_filtering/metadata.pkl', 'wb') as f:\n",
    "    pickle.dump(metadata, f)\n",
    "print(\"✓ Saved: metadata.pkl\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ALL FILES SAVED SUCCESSFULLY!\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nNext step: Run 02_cf_evaluation.ipynb to evaluate the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0035fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
